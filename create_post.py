import os
import re
import json
import mimetypes
import pandas as pd
from PIL import Image
from pathlib import Path
from datetime import datetime
from typing import List, Dict, Any, Optional

from dotenv import load_dotenv
from openai import OpenAI
from google import genai
from google.genai import types

# ==============================================================================
# 0. ì „ì—­ ì„¤ì •
# ==============================================================================
MIN_WORDS = 1500
OPENAI_MODEL = "gpt-5.2"
MAX_IMAGES_PER_POST = 4

# ìˆ˜ìµí™”(affiliate) ê¸°ëŠ¥ ON/OFF
ENABLE_MONETIZATION = True

# ==============================================================================
# PROVIDER ACTIVATION FLAGS
# ==============================================================================
# Set to True when affiliate partnership is ACTIVE and APPROVED
# Set to False to disable ALL affiliate content for that provider
# When False:
#   - No affiliate disclosures rendered for that provider
#   - No offer shortcodes inserted for that provider
#   - CTA blocks show neutral "Deals hub" without commission claims
# ==============================================================================
AMAZON_ASSOCIATES_ACTIVE = False   # Set True after Amazon approval
BOOKING_AFFILIATE_ACTIVE = False   # Set True after Booking.com approval
KLOOK_AFFILIATE_ACTIVE = False     # Set True after Klook approval
VIATOR_AFFILIATE_ACTIVE = False    # Set True after Viator approval
GETYOURGUIDE_AFFILIATE_ACTIVE = False

# Provider to slot prefix mapping
PROVIDER_SLOT_PREFIX = {
    "amazon": "AMZ_",
    "booking": "KOREA_HOTEL",
    "klook": "KOREA_",  # Default for tours
    "viator": "VIA_",
    "getyourguide": "GYG_",
}

# ==============================================================================
# ACTIVE_SLOTS: ìŠ¬ë¡¯ë³„ í™œì„±í™” ì—¬ë¶€
# - ë¹„í™œì„± ìŠ¬ë¡¯ì€ disclosure, offer injection ëª¨ë‘ ìŠ¤í‚µ
# - Provider flagê°€ Falseë©´ í•´ë‹¹ providerì˜ ëª¨ë“  ìŠ¬ë¡¯ ìë™ ë¹„í™œì„±í™”
# ==============================================================================
ACTIVE_SLOTS: Dict[str, bool] = {
    # Klook tours
    "KOREA_TOUR_DEALS": KLOOK_AFFILIATE_ACTIVE,
    "KOREA_DMZ_TOUR": KLOOK_AFFILIATE_ACTIVE,
    "KOREA_PALACE_TOUR": KLOOK_AFFILIATE_ACTIVE,
    "KOREA_KPOP_TOUR": KLOOK_AFFILIATE_ACTIVE,
    "KOREA_DAYTRIP": KLOOK_AFFILIATE_ACTIVE,
    "KOREA_FOOD_TOUR": KLOOK_AFFILIATE_ACTIVE,
    # Booking.com hotels
    "KOREA_HOTEL_DEALS": BOOKING_AFFILIATE_ACTIVE,
    "KOREA_HOTEL_LUXURY": BOOKING_AFFILIATE_ACTIVE,
    "KOREA_HOTEL_MIDRANGE": BOOKING_AFFILIATE_ACTIVE,
    "KOREA_HOTEL_BUDGET": BOOKING_AFFILIATE_ACTIVE,
    "KOREA_HANOK_STAY": BOOKING_AFFILIATE_ACTIVE,
    "KOREA_BUSAN_HOTEL": BOOKING_AFFILIATE_ACTIVE,
    # Amazon products
    "AMZ_TRAVEL_ESSENTIALS": AMAZON_ASSOCIATES_ACTIVE,
    "AMZ_KSTYLE_FEATURED": AMAZON_ASSOCIATES_ACTIVE,
    "AMZ_KOREA_ADAPTER": AMAZON_ASSOCIATES_ACTIVE,
    "AMZ_PORTABLE_WIFI": AMAZON_ASSOCIATES_ACTIVE,
    "AMZ_POWER_BANK": AMAZON_ASSOCIATES_ACTIVE,
    "AMZ_KBEAUTY_MASKS": AMAZON_ASSOCIATES_ACTIVE,
}

# í˜„ì¬ ì—°ë„ (í”„ë¡¬í”„íŠ¸ì—ì„œ ì‚¬ìš©)
CURRENT_YEAR = datetime.now().year

# ==============================================================================
# AMAZON ASSOCIATES COMPLIANCE
# ==============================================================================
# EXACT required disclosure text (do not modify!)
AMAZON_DISCLOSURE_EXACT = "As an Amazon Associate I earn from qualifying purchases."

# ==============================================================================
# COMPLIANCE GUARDRAILS
# ==============================================================================
# âš ï¸ IMPORTANT: Amazon Associates Program Policy
# - NEVER use redirect links (/go/, /out/, /redirect/) for Amazon products
# - Amazon links MUST be direct links to amazon.com domains
# - All Amazon affiliate content must include AMAZON_DISCLOSURE_EXACT
# - Disclosure must appear within first 30 lines of content body
# ==============================================================================

# ==============================================================================
# 1. ì„¤ì • ë° ì´ˆê¸°í™”
# ==============================================================================
BASE_PROJECT_DIR = Path("C:/Users/uesr/dev")
HUGO_CONTENT_DIR = Path("C:/Users/uesr/myblog/content/posts")
HUGO_IMAGE_DIR = Path("C:/Users/uesr/myblog/static/images")

load_dotenv(dotenv_path=BASE_PROJECT_DIR / ".env")

OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
GEMINI_API_KEY = os.getenv("GEMINI_API_KEY")

if not OPENAI_API_KEY:
    raise RuntimeError("OPENAI_API_KEY Missing")
if not GEMINI_API_KEY:
    raise RuntimeError("GEMINI_API_KEY Missing")

clientOpenAI = OpenAI(api_key=OPENAI_API_KEY)
clientGoogle = genai.Client(api_key=GEMINI_API_KEY)

# ==============================================================================
# 2. ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜
# ==============================================================================
def slugify(text: str, max_len: int = 60) -> str:
    t = (text or "").strip().lower()
    t = re.sub(r"['\"]", "", t)
    t = re.sub(r"[^a-z0-9\s-]", " ", t)
    t = re.sub(r"\s+", " ", t).strip()
    t = t.replace(" ", "-")
    return t[:max_len].strip("-") or "post"


def count_words(md: str) -> int:
    return len(re.findall(r"[A-Za-z0-9']+", md or ""))


def clean_markdown_response(text: str) -> str:
    text = (text or "").strip()
    pattern = r"^```(?:markdown)?\s*(.*)\s*```$"
    match = re.search(pattern, text, re.DOTALL)
    if match:
        return match.group(1).strip()
    return text

def prepend_block(md: str, block: str) -> str:
    """Always prepend a block to the top of markdown."""
    if not block:
        return md or ""
    return block.strip() + "\n\n" + (md or "").lstrip()


def strip_first_h1(md: str) -> str:
    """
    Remove the first Markdown H1 line (# ...) to avoid duplicate H1
    when the Hugo theme already renders .Title as H1.
    """
    if not md:
        return ""
    lines = md.splitlines()
    out = []
    removed = False
    for line in lines:
        if (not removed) and line.startswith("# "):
            removed = True
            continue
        out.append(line)
    return "\n".join(out).lstrip()


def extract_first_image_url(md: str) -> str:
    """Extract first markdown image URL: ![alt](url)"""
    if not md:
        return ""
    m = re.search(r'!\[[^\]]*\]\(([^)]+)\)', md)
    return (m.group(1).strip() if m else "")



def convert_to_webp_with_alt(input_path, output_dir, alt_text=None, quality=85):
    if not input_path:
        return None
    input_path = Path(input_path)
    output_dir = Path(output_dir)
    output_dir.mkdir(parents=True, exist_ok=True)

    webp_filename = f"{input_path.stem}.webp"
    webp_path = output_dir / webp_filename

    try:
        with Image.open(input_path) as img:
            img.save(webp_path, "webp", quality=quality)
    except Exception as e:
        print(f"âŒ WebP Conversion Error: {e}")
        return None

    if not webp_path.exists():
        print(f"âŒ WebP file not found after save: {webp_path}")
        return None
    
    if not alt_text:
        alt_text = input_path.stem
    return f'![{alt_text}](/images/{webp_filename})'


def insert_after_h1(md: str, block: str) -> str:
    if not md or not block:
        return md or ""
    lines = md.splitlines()
    out = []
    inserted = False
    for line in lines:
        out.append(line)
        if not inserted and line.startswith("# "):
            out.append("")
            out.append(block)
            out.append("")
            inserted = True
    return "\n".join(out)


def append_section(md: str, section_md: str) -> str:
    if not section_md:
        return md
    return (md or "").rstrip() + "\n\n" + section_md.strip() + "\n"


def build_faq_section(faq: List[Dict[str, str]]) -> str:
    if not faq:
        return ""
    out = ["## FAQ"]
    for item in faq[:8]:
        q = item.get("q", "").strip()
        a = item.get("a", "").strip()
        if q and a:
            out.append(f"\n**Q: {q}**\n\n{a}")
    return "\n".join(out).strip()


def build_quick_info_box(quick: Dict[str, Any], keyword: str) -> str:
    area = (quick.get("area") or "").strip() or keyword
    best_time = (quick.get("best_time") or "").strip() or "varies by season"
    budget = (quick.get("budget") or "").strip() or "depends on your itinerary"
    transport = (quick.get("transport") or "").strip() or "subway + bus in most cities"
    recommended_for = (quick.get("recommended_for") or "").strip() or "first-time visitors"
    tldr = (quick.get("tldr") or "").strip()

    lines = [
        "> **Quick Info**",
        f"> - ğŸ“ Area: {area}",
        f"> - ğŸ•’ Best time: {best_time}",
        f"> - ğŸ’° Budget: {budget}",
        f"> - ğŸš‡ Getting there: {transport}",
        f"> - ğŸ‘¥ Best for: {recommended_for}",
    ]
    if tldr:
        lines.append(f"> - âœ… TL;DR: {tldr}")
    return "\n".join(lines)


# ------------------------------------------------------------------------------
# Hugo Shortcode helpers
# ------------------------------------------------------------------------------
def sc_offer(slot: str, pos: str = "mid") -> str:
    # Hugo shortcode: {{< offer slot="..." pos="..." >}}
    return f'{{{{< offer slot="{slot}" pos="{pos}" >}}}}'


def sc_lead(slot: str, pos: str = "mid") -> str:
    # (ì˜µì…˜) ë‚˜ì¤‘ì— lead shortcode ë§Œë“¤ ë•Œ ì‚¬ìš©
    return f'{{{{< lead slot="{slot}" pos="{pos}" >}}}}'


# ------------------------------------------------------------------------------
# Monetization inference + disclosure
# ------------------------------------------------------------------------------
def is_slot_active(slot: str) -> bool:
    """Check if a slot is active in ACTIVE_SLOTS config."""
    return ACTIVE_SLOTS.get(slot, False)


def filter_active_slots(slots: List[str]) -> List[str]:
    """Filter slots to only include active ones."""
    return [s for s in slots if is_slot_active(s)]


def has_any_active_slot(monetize: Dict[str, Any]) -> bool:
    """
    Check if monetize config has at least one active slot.
    Used for gating disclosure/offer injection.
    """
    if not monetize:
        return False
    slots = monetize.get("slots", {}) or {}
    all_slots = (slots.get("top", []) or []) + (slots.get("bottom", []) or [])
    return any(is_slot_active(s) for s in all_slots)


def has_active_amazon_slot(monetize: Dict[str, Any]) -> bool:
    """Check if any active Amazon slot exists."""
    if not monetize:
        return False
    slots = monetize.get("slots", {}) or {}
    all_slots = (slots.get("top", []) or []) + (slots.get("bottom", []) or [])
    amazon_slots = [s for s in all_slots if s.startswith("AMZ_")]
    return any(is_slot_active(s) for s in amazon_slots)


def infer_monetize(category: str) -> Dict[str, Any]:
    """
    ì¹´í…Œê³ ë¦¬ ê¸°ë°˜ ìˆ˜ìµí™” ì„¤ì • ì¶”ë¡ .
    - k-travel/k-lifestyle: booking intent (hotel + tour + amazon essentials)
    - k-fashion/k-beauty: shopping intent (amazon)
    - ë‚˜ë¨¸ì§€: info intent
    
    Note: ë°˜í™˜ëœ ìŠ¬ë¡¯ì€ ACTIVE_SLOTSì—ì„œ í™œì„±í™”ëœ ê²ƒë§Œ ì‹¤ì œ ì‚¬ìš©ë¨.
    """
    cat = (category or "").lower()

    if cat in ["k-travel", "k-lifestyle"]:
        base_slots = {
            "top": ["KOREA_TOUR_DEALS", "KOREA_HOTEL_DEALS", "AMZ_TRAVEL_ESSENTIALS"],
            "bottom": ["KOREA_TOUR_DEALS", "KOREA_HOTEL_DEALS"],
        }
        return {
            "intent": "booking",
            "verticals": ["hotel", "tour", "amazon"],
            "slots": {
                "top": filter_active_slots(base_slots["top"]),
                "bottom": filter_active_slots(base_slots["bottom"]),
            },
        }

    if cat in ["k-fashion", "k-beauty"]:
        base_slots = {
            "top": ["AMZ_KSTYLE_FEATURED"],
            "bottom": ["AMZ_KSTYLE_FEATURED"],
        }
        return {
            "intent": "shopping",
            "verticals": ["amazon"],
            "slots": {
                "top": filter_active_slots(base_slots["top"]),
                "bottom": filter_active_slots(base_slots["bottom"]),
            },
        }

    return {
        "intent": "info",
        "verticals": [],
        "slots": {"top": [], "bottom": []},
    }


def build_affiliate_disclosure_md(monetize: Dict[str, Any]) -> str:
    """
    FTC/Amazon ì»´í”Œë¼ì´ì–¸ìŠ¤ disclosure ìƒì„±.
    - ACTIVE providerê°€ í•˜ë‚˜ë¼ë„ ìˆì„ ë•Œë§Œ disclosure í‘œì‹œ
    - Amazon ìŠ¬ë¡¯ì´ í™œì„±í™”ëœ ê²½ìš° AMAZON_DISCLOSURE_EXACT ë¬¸êµ¬ í•„ìˆ˜
    - Providerê°€ ë¹„í™œì„±í™”ë©´ í•´ë‹¹ disclosure ìƒëµ
    """
    if not monetize:
        return ""
    
    # Monetization gating: í™œì„± ìŠ¬ë¡¯ì´ ì—†ìœ¼ë©´ disclosure ë¶ˆí•„ìš”
    if not has_any_active_slot(monetize):
        # ë¹„í™œì„± ìƒíƒœì—ì„œëŠ” ì¤‘ë¦½ì  ë¬¸êµ¬ë§Œ í‘œì‹œ (ì»¤ë¯¸ì…˜ ì–¸ê¸‰ ì—†ìŒ)
        return ""

    verticals = monetize.get("verticals", []) or []
    if not verticals:
        return ""

    lines = []
    
    # ì¼ë°˜ FTC disclosure (í•­ìƒ ë¨¼ì €)
    lines.append("> **Disclosure**: This post may contain affiliate links. If you purchase through them, I may earn a commission at no extra cost to you.")
    
    # Amazon Associate í•„ìˆ˜ ë¬¸êµ¬ - EXACT TEXT REQUIRED
    # Amazon ìŠ¬ë¡¯ì´ í™œì„±í™”ëœ ê²½ìš°ì—ë§Œ (AMAZON_ASSOCIATES_ACTIVE=True)
    if has_active_amazon_slot(monetize) and AMAZON_ASSOCIATES_ACTIVE:
        # âš ï¸ Do NOT modify this text - exact wording required by Amazon
        lines.append(f"> **{AMAZON_DISCLOSURE_EXACT}**")
    
    return "\n".join(lines)


def build_neutral_cta_block(keyword: str, position: str = "top") -> str:
    """
    ì¤‘ë¦½ì  CTA ë¸”ë¡ (ì»¤ë¯¸ì…˜ ì–¸ê¸‰ ì—†ìŒ).
    Providerê°€ ë¹„í™œì„±í™” ìƒíƒœì¼ ë•Œ ì‚¬ìš©.
    """
    if position == "top":
        return f"""## Before you start planning

If you're researching **{keyword}**, check out our curated resources:

- ğŸ“š [Browse our Korea travel guides](/deals/)

Bookmark this page and come back when you're ready to plan!
"""
    return """## Ready to explore more?

Check out our other Korea travel guides for more inspiration.
"""


def build_mini_disclosure() -> str:
    """
    ì˜¤í¼ ì‚½ì… ì „ í‘œì‹œí•  ë¯¸ë‹ˆ disclosure.
    FTC ê°€ì´ë“œë¼ì¸ ì¤€ìˆ˜ë¥¼ ìœ„í•´ ê° ì˜¤í¼ ì„¹ì…˜ ì•ì— ë°°ì¹˜.
    """
    return "*Disclosure: This section may contain affiliate links. We may earn a commission at no extra cost to you.*"


# ------------------------------------------------------------------------------
# Deals í˜ì´ì§€ URL ë§¤í•‘ (/go/ ë¦¬ë‹¤ì´ë ‰íŠ¸ ëŒ€ì‹  ì½˜í…ì¸  í—ˆë¸Œ ì‚¬ìš©)
# ------------------------------------------------------------------------------
DEALS_URLS = {
    "tours": "/deals/korea-tours/",
    "hotels": "/deals/korea-hotels/",
    "essentials": "/deals/korea-essentials/",
}


def build_cta_block(bundle: Dict[str, Any], keyword: str, position: str = "top") -> str:
    """
    CTA ë¸”ë¡ ìƒì„±.
    - /go/ ë¦¬ë‹¤ì´ë ‰íŠ¸ ëŒ€ì‹  /deals/ ì½˜í…ì¸  í—ˆë¸Œë¡œ ì—°ê²°
    - Amazonì€ deals í˜ì´ì§€ ë‚´ì—ì„œë§Œ ë…¸ì¶œ (direct link ì •ì±… ì¤€ìˆ˜)
    - Monetization gating: í™œì„± ìŠ¬ë¡¯ì´ ì—†ìœ¼ë©´ CTA ìµœì†Œí™”
    
    âš ï¸ COMPLIANCE: Amazon links are ONLY on /deals/ pages (direct links).
       NEVER use /go/ redirects for Amazon products.
    """
    monetize = bundle.get("monetize") or {}
    intent = (monetize.get("intent") or "").lower()
    
    # Monetization gating: í™œì„± ìŠ¬ë¡¯ì´ ì—†ìœ¼ë©´ info intentì²˜ëŸ¼ ì²˜ë¦¬
    if not has_any_active_slot(monetize):
        intent = "info"

    # booking intent: í˜¸í…”/íˆ¬ì–´ â†’ /deals/ í˜ì´ì§€ë¡œ ìœ ë„
    if intent == "booking":
        if position == "top":
            lines = [
                "## Before you start planning",
                "",
                f"If you're thinking about **{keyword}**, check current prices and deals first:",
                "",
                f"- ğŸ« [Compare Korea Tours & Day Trips]({DEALS_URLS['tours']})",
                f"- ğŸ¨ [Find Hotels & Accommodations]({DEALS_URLS['hotels']})",
                f"- ğŸ’ [Get Travel Essentials]({DEALS_URLS['essentials']})",
                "",
                "**Tip:** Pick **free-cancellation** options if you're still deciding.",
            ]
            return "\n".join(lines).strip()

        # bottom
        lines = [
            "## Ready to book your trip?",
            "",
            "Take one small step now:",
            "",
            f"- [Compare tours and tickets]({DEALS_URLS['tours']})",
            f"- [Check hotel prices]({DEALS_URLS['hotels']})",
            "",
            "Even checking prices today can save money later.",
        ]
        return "\n".join(lines).strip()

    # shopping intent: K-beauty/K-fashion â†’ deals í˜ì´ì§€ë¡œ ìœ ë„
    if intent == "shopping":
        if position == "top":
            lines = [
                "## Quick picks",
                "",
                "Looking for curated K-style products?",
                "",
                f"- ğŸ’ [Browse Travel & Style Essentials]({DEALS_URLS['essentials']})",
                "",
                "Or keep reading for our in-depth recommendations below.",
            ]
        else:
            lines = [
                "## What to buy next",
                "",
                "Ready to shop? Check out our curated picks:",
                "",
                f"- [Travel Essentials & K-Beauty]({DEALS_URLS['essentials']})",
            ]
        return "\n".join(lines).strip()

    # info intent: ê¸°ë³¸ ë¬¸êµ¬ë§Œ (ì˜¤í¼ ì—†ìŒ)
    if position == "top":
        return (
            "## Before you dive in\n\n"
            "If any part of this guide feels useful, take 10 seconds to bookmark it.\n"
        )
    return (
        "## What you can do next\n\n"
        "Pick just **one** action from this guide and do it todayâ€”small steps add up.\n"
    )


# ==============================================================================
# 3. AI ë¦¬ì„œì¹˜ & í”„ë¡¬í”„íŠ¸ ìƒì„±
# ==============================================================================
def research_with_ai(keyword: str) -> str:
    print(f"ğŸ” [Research] Searching for: '{keyword}'...")
    try:
        prompt = f"""
As a professional researcher, perform a web search on: '{keyword}' (Korean context).
Focus on:
- what this is and why people search for it
- typical prices, tickets, or tour options if relevant
- important locations and seasonal tips
- pitfalls, common mistakes, or things people often regret
"""
        response = clientOpenAI.responses.create(
            model="gpt-4o",
            input=prompt,
            tools=[
                {
                    "type": "web_search_preview",
                    "user_location": {"type": "approximate", "country": "KR"},
                }
            ],
        )
        text = (getattr(response, "output_text", "") or "").strip()
        if text:
            print("âœ… [Research] Data collected.")
            return text
        else:
            print("âš ï¸ [Research] Empty output_text from responses API, falling back to chat.completions...")

    except Exception as e:
        print(f"âš ï¸ Research via responses API failed, falling back to chat.completions: {e}")

    try:
        fallback_prompt = f"""
You are a research assistant for an English Korea travel & lifestyle blog.

Without web browsing, write a concise but useful research summary
about the topic: "{keyword}".

Focus on:
- what it is / basic background
- why visitors care about it
- practical tips and example prices in KRW if possible
- common mistakes or misunderstandings
"""
        resp2 = clientOpenAI.chat.completions.create(
            model=OPENAI_MODEL,
            messages=[
                {
                    "role": "system",
                    "content": "You summarize topics for an English Korea travel & lifestyle blog.",
                },
                {"role": "user", "content": fallback_prompt},
            ],
        )
        text2 = (resp2.choices[0].message.content or "").strip()
        if text2:
            print("âœ… [Research] Fallback summary generated.")
            return text2
    except Exception as e2:
        print(f"âŒ Research fallback error: {e2}")

    print("âš ï¸ Research failed completely. Using minimal placeholder summary.")
    return f"General background and practical information about '{keyword}' in Korea."


def create_dynamic_image_prompt(topic: str) -> str:
    print(f"ğŸ¨ [Prompt Gen] creating prompt for '{topic}'...")
    try:
        prompt = f"""
Create a photorealistic image prompt about: "{topic}".

Include:
- clear subject and composition (camera angle, distance)
- specific setting in Korea (street, market, station, palace, river, etc.)
- realistic lighting and mood (time of day, weather)
- photographic style (lens, depth of field, film/digital, grain)

Rules:
- absolutely NO text, letters, numbers, logos, or watermarks in the image
- no posters, menus, or signs with readable text

Return ONE concise paragraph in English.
"""
        resp = clientOpenAI.chat.completions.create(
            model=OPENAI_MODEL,
            messages=[{"role": "user", "content": prompt}],
        )
        return (resp.choices[0].message.content or "").strip().replace('"', "")
    except Exception as e:
        print(f"âŒ [Prompt Gen] Error: {e}")
        return (
            f"A high-quality photorealistic travel photo of {topic}, candid street "
            "photography, 35mm film grain, shallow depth of field, no text."
        )


# ==============================================================================
# 4. ì´ë¯¸ì§€ ìƒì„± (Gemini ì´ë¯¸ì§€ ìƒì„±)
# ==============================================================================
def _save_binary_file(path: Path, data: bytes):
    path.parent.mkdir(parents=True, exist_ok=True)
    with open(path, "wb") as f:
        f.write(data)


def _generate_with_google_banana(prompt: str, filename_base: str) -> Optional[Path]:
    print(f"ğŸŒ [Nano Banana] Generating: {filename_base}...")
    try:
        model = "gemini-3-pro-image-preview"

        contents = [
            types.Content(
                role="user",
                parts=[types.Part.from_text(text=prompt)],
            )
        ]

        gc_kwargs: Dict[str, Any] = {"response_modalities": ["IMAGE", "TEXT"]}
        if hasattr(types, "ImageConfig"):
            try:
                gc_kwargs["image_config"] = types.ImageConfig(image_size="1K")
            except Exception as e_ic:
                print(f"âš ï¸ ImageConfig error, continuing without it: {e_ic}")

        generate_content_config = types.GenerateContentConfig(**gc_kwargs)

        for chunk in clientGoogle.models.generate_content_stream(
            model=model,
            contents=contents,
            config=generate_content_config,
        ):
            if (
                not chunk.candidates
                or chunk.candidates[0].content is None
                or not chunk.candidates[0].content.parts
            ):
                continue

            for part in chunk.candidates[0].content.parts:
                inline = getattr(part, "inline_data", None)
                if inline and inline.data:
                    ext = mimetypes.guess_extension(inline.mime_type) or ".png"
                    path = HUGO_IMAGE_DIR / f"{filename_base}{ext}"
                    _save_binary_file(path, inline.data)
                    return path

            text_attr = getattr(chunk, "text", None)
            if text_attr:
                print(f"   (Text output: {text_attr})")

    except Exception as e:
        print(f"âŒ Nano Banana Error: {e}")
        return None

    print("âš ï¸ Nano Banana did not return any image bytes.")
    return None

def sanitize_ai_artifacts(md: str) -> str:
    if not md:
        return ""
    # í”í•œ AI ë©”íƒ€ ë¬¸êµ¬ ì œê±°/ì™„í™”
    md = re.sub(r"\byour summary supports\b.*?(?:\n|$)", "", md, flags=re.IGNORECASE)
    md = re.sub(r"\baccording to the research summary\b.*?(?:\n|$)", "", md, flags=re.IGNORECASE)
    md = re.sub(r"\n{3,}", "\n\n", md)
    return md.strip()

def generate_image(topic: str, filename_base: str, alt: str) -> str:
    full_prompt = create_dynamic_image_prompt(topic)
    saved_path = _generate_with_google_banana(full_prompt, filename_base)

    if saved_path:
        tag = convert_to_webp_with_alt(saved_path, HUGO_IMAGE_DIR, alt)
        if tag:
            print(f"âœ… [Image] OK: {filename_base} -> {tag}")
            return tag

    print(f"âŒ [Image] Failed: {filename_base} (topic={topic})")
    return ""


def inject_images(content: str, slug: str, title: str) -> str:
    lines = content.split("\n")
    out = []
    img_cnt = 0

    for line in lines:
        out.append(line)
        if line.startswith("## ") and img_cnt < MAX_IMAGES_PER_POST:
            h2 = line[3:].strip()
            prompt_topic = f"{title} - {h2}" if len(h2) < 40 else h2
            fname = f"{slug}-h2-{img_cnt}"
            tag = generate_image(prompt_topic, fname, h2)
            if tag:
                out.append("")
                out.append(tag)
                out.append("")
            img_cnt += 1
    return "\n".join(out)


# ------------------------------------------------------------------------------
# Offer injection (H2 ê¸°ë°˜ ìˆ˜ìµí™” ìˆì½”ë“œ ì‚½ì…)
# ------------------------------------------------------------------------------
# H2 í‚¤ì›Œë“œ â†’ ìŠ¬ë¡¯ ë§¤í•‘ ê·œì¹™
H2_OFFER_RULES: List[Dict[str, Any]] = [
    {
        "keywords": ["where to book", "tickets", "pass", "tour", "how to book"],
        "slots": ["KOREA_TOUR_DEALS", "KOREA_HOTEL_DEALS"],
        "intents": ["booking", "info"],  # ì ìš© ê°€ëŠ¥í•œ intent
    },
    {
        "keywords": ["typical price", "budget", "cost", "how much", "price"],
        "slots": ["KOREA_TOUR_DEALS"],
        "intents": ["booking", "info"],
    },
    {
        "keywords": ["what to pack", "essentials", "adapter", "packing", "bring", "gear"],
        "slots": ["AMZ_TRAVEL_ESSENTIALS"],
        "intents": ["booking", "info"],
    },
    {
        "keywords": ["beauty", "skincare", "makeup", "cosmetic"],
        "slots": ["AMZ_KSTYLE_FEATURED"],
        "intents": ["shopping"],
    },
    {
        "keywords": ["fashion", "style", "outfit", "clothing", "wear"],
        "slots": ["AMZ_KSTYLE_FEATURED"],
        "intents": ["shopping"],
    },
    {
        "keywords": ["buy", "shop", "purchase", "deal", "discount"],
        "slots": ["AMZ_KSTYLE_FEATURED"],
        "intents": ["shopping"],
    },
]

# ì „ì—­ ìŠ¬ë¡¯ë³„ ì‚½ì… ìƒí•œ
MAX_SLOT_PER_PAGE = 2


def _match_h2_to_slots(h2_text: str, intent: str) -> List[str]:
    """
    H2 í…ìŠ¤íŠ¸ì™€ intentì— ë”°ë¼ ì‚½ì…í•  ìŠ¬ë¡¯ ë¦¬ìŠ¤íŠ¸ ë°˜í™˜.
    ë§¤ì¹­ë˜ëŠ” ì²« ë²ˆì§¸ ê·œì¹™ì˜ ìŠ¬ë¡¯ë§Œ ë°˜í™˜ (ê³¼ë„í•œ ì‚½ì… ë°©ì§€).
    """
    h2_lower = h2_text.lower()
    intent_lower = intent.lower()

    for rule in H2_OFFER_RULES:
        # intent ì²´í¬
        if intent_lower not in [i.lower() for i in rule.get("intents", [])]:
            continue

        # í‚¤ì›Œë“œ ë§¤ì¹­
        for kw in rule.get("keywords", []):
            if kw.lower() in h2_lower:
                return rule.get("slots", [])

    return []


def inject_offers(content_md: str, monetize: Dict[str, Any]) -> str:
    """
    H2 í—¤ë”© ì•„ë˜ì— ì˜¤í¼ ìˆì½”ë“œë¥¼ ìë™ ì‚½ì….

    ê·œì¹™:
    - H2ì— íŠ¹ì • í‚¤ì›Œë“œê°€ í¬í•¨ë˜ë©´ í•´ë‹¹ ìŠ¬ë¡¯ì˜ offer ì‚½ì…
    - í˜ì´ì§€ë‹¹ ë™ì¼ ìŠ¬ë¡¯ì€ ìµœëŒ€ MAX_SLOT_PER_PAGEíšŒê¹Œì§€ë§Œ
    - intentê°€ 'info'ì¸ ê²½ìš° ì˜¤í¼ ì‚½ì… ì•ˆ í•¨ (ë‹¨, íŠ¹ì • í‚¤ì›Œë“œ ë§¤ì¹­ ì‹œ ì˜ˆì™¸)
    - ACTIVE_SLOTSì—ì„œ ë¹„í™œì„±í™”ëœ ìŠ¬ë¡¯ì€ ì‚½ì…í•˜ì§€ ì•ŠìŒ
    - ê° ì˜¤í¼ ì•ì— ë¯¸ë‹ˆ disclosure ì‚½ì… (FTC compliance)

    Args:
        content_md: ë³¸ë¬¸ ë§ˆí¬ë‹¤ìš´
        monetize: infer_monetize()ì—ì„œ ë°˜í™˜ëœ ë”•ì…”ë„ˆë¦¬

    Returns:
        ì˜¤í¼ê°€ ì‚½ì…ëœ ë§ˆí¬ë‹¤ìš´
    """
    if not monetize:
        return content_md
    
    # Monetization gating: í™œì„± ìŠ¬ë¡¯ì´ ì—†ìœ¼ë©´ ì˜¤í¼ ì‚½ì… ìŠ¤í‚µ
    if not has_any_active_slot(monetize):
        return content_md

    intent = (monetize.get("intent") or "").lower()

    # info intentëŠ” H2 ë§¤ì¹­ ì˜ˆì™¸ ì¼€ì´ìŠ¤(packing ë“±)ë§Œ ì²˜ë¦¬
    if intent == "info":
        # info intentì—¬ë„ travel essentials ê°™ì€ ê±´ ë„£ì„ ìˆ˜ ìˆìŒ
        pass

    lines = content_md.split("\n")
    out: List[str] = []
    slot_count: Dict[str, int] = {}  # ìŠ¬ë¡¯ë³„ ì‚½ì… íšŸìˆ˜ ì¶”ì 
    disclosure_inserted = False  # ë¯¸ë‹ˆ disclosure í•œ ë²ˆë§Œ ì‚½ì…

    i = 0
    while i < len(lines):
        line = lines[i]
        out.append(line)

        # H2 ê°ì§€
        if line.startswith("## "):
            h2_text = line[3:].strip()

            # H2ì— ë§ëŠ” ìŠ¬ë¡¯ ì°¾ê¸°
            matched_slots = _match_h2_to_slots(h2_text, intent)
            
            # ACTIVE_SLOTS í•„í„°ë§ ì ìš©
            matched_slots = filter_active_slots(matched_slots)

            # ì‚½ì…í•  ìŠ¬ë¡¯ í•„í„°ë§ (ì¤‘ë³µ ìƒí•œ ì²´í¬)
            slots_to_insert = []
            for slot in matched_slots:
                current = slot_count.get(slot, 0)
                if current < MAX_SLOT_PER_PAGE:
                    slots_to_insert.append(slot)
                    slot_count[slot] = current + 1
                    break  # H2ë‹¹ í•˜ë‚˜ì˜ ìŠ¬ë¡¯ë§Œ ì‚½ì…

            if slots_to_insert:
                # H2 ë°”ë¡œ ë‹¤ìŒ ì¤„ í™•ì¸ (ì´ë¯¸ì§€ íƒœê·¸ ë“± ê±´ë„ˆë›°ê¸°)
                # ì´ë¯¸ì§€/ë¹ˆì¤„ì„ ê±´ë„ˆë›´ ë’¤ ì˜¤í¼ ì‚½ì…
                j = i + 1
                insert_lines = []

                # ë‹¤ìŒ ì¤„ë“¤ ìˆ˜ì§‘ (ì´ë¯¸ì§€, ë¹ˆì¤„)
                while j < len(lines):
                    next_line = lines[j]
                    # ë¹ˆì¤„ì´ë‚˜ ì´ë¯¸ì§€ íƒœê·¸ëŠ” ë¨¼ì € outì— ì¶”ê°€
                    if next_line.strip() == "" or next_line.strip().startswith("!["):
                        insert_lines.append(next_line)
                        j += 1
                    else:
                        break

                # ìˆ˜ì§‘í•œ ì¤„ë“¤ ì¶”ê°€
                out.extend(insert_lines)

                # ì²« ë²ˆì§¸ ì˜¤í¼ ì‚½ì… ì‹œ ë¯¸ë‹ˆ disclosure ì¶”ê°€ (FTC compliance)
                if not disclosure_inserted:
                    out.append("")
                    out.append(build_mini_disclosure())
                    disclosure_inserted = True

                # ì˜¤í¼ ì‚½ì… (ë¹ˆì¤„ + ì˜¤í¼ + ë¹ˆì¤„)
                for slot in slots_to_insert:
                    out.append("")
                    out.append(sc_offer(slot, "mid"))
                    out.append("")

                # ì¸ë±ìŠ¤ ì¡°ì •
                i = j
                continue

        i += 1

    # ê²°ê³¼ ì •ë¦¬: ì—°ì† ë¹ˆì¤„ 3ê°œ ì´ìƒ â†’ 2ê°œë¡œ
    result = "\n".join(out)
    result = re.sub(r"\n{4,}", "\n\n\n", result)

    return result


# ==============================================================================
# 5. ì½˜í…ì¸  ìƒì„±
# ==============================================================================
def create_blog_bundle(keyword: str, research: str) -> Dict[str, Any]:
    print("âœï¸ [Step 1] Planning (intent-based)...")
    plan_prompt = f"""
You are planning a Korea travel/lifestyle blog post with clear user intent.

Topic (Korean): "{keyword}"

Research summary:
{research}

=== STEP 1: DETERMINE INTENT ===
First, determine the user intent based on the topic:
- "booking": User wants to BOOK something (tours, hotels, tickets, passes)
- "shopping": User wants to BUY products (beauty, fashion, electronics)
- "info": User wants INFORMATION only (culture, history, tips, guides)

=== STEP 2: APPLY INTENT-BASED CONSTRAINTS ===

Return ONE JSON object with these keys:

1. **intent**: MUST be one of ["booking", "shopping", "info"]

2. **category**: one of ["k-beauty","k-drama","k-fashion","k-food",
   "k-lifestyle","k-movie","k-music","k-news","k-tech","k-travel",
   "k-trends","learn-korean"]

3. **seo_title**: SEO-optimized English title that MUST include:
   - either a year (e.g. {CURRENT_YEAR}) OR a number (e.g. Top 7)
   - AND intent-specific words:
     * IF intent="booking": MUST include one of ["tours", "how to book", "prices", "tickets", "pass"]
     * IF intent="shopping": MUST include one of ["where to buy", "best", "prices", "review", "top"]
     * IF intent="info": MUST include one of ["guide", "tips", "itinerary", "things to know", "complete"]

4. **slug**: short lowercase-hyphen slug (3-80 chars)

5. **meta_description**: 140-160 chars. Intent-specific:
   * booking: mention prices, booking, best tours
   * shopping: mention where to buy, best products, prices
   * info: mention guide, tips, what to know

6. **tags**: array of 6-10 short lowercase tags (max 2 words each)

7. **quick_info**: object with keys [area, best_time, budget, transport, recommended_for, tldr]

8. **faq**: array of 4-6 objects {{"q": "...", "a": "..."}}.
   * booking: At least 3 questions about money/booking
   * shopping: At least 3 questions about prices/where to buy
   * info: At least 3 questions about practical tips

9. **outline**: array of 5-8 H2-style section titles. Intent-specific:
   * IF intent="booking", MUST include:
     - "Where to Book {{topic}} Tours and Tickets"
     - "Typical Prices & Budget Examples"
     - "Money-Saving Tips"
   * IF intent="shopping", MUST include:
     - "Where to Buy {{topic}}"
     - "Price Ranges & What to Expect"
     - "Best {{topic}} Recommendations"
   * IF intent="info", MUST include:
     - "Complete Guide to {{topic}}"
     - "Tips for First-Time Visitors"
     - "What to Know Before You Go"

Return ONLY the JSON object. No explanation.
"""
    resp_plan = clientOpenAI.chat.completions.create(
        model=OPENAI_MODEL,
        response_format={"type": "json_object"},
        messages=[{"role": "user", "content": plan_prompt}],
    )
    plan = json.loads(resp_plan.choices[0].message.content)

    # monetize ìë™ ì¶”ë¡ (ìµœì†Œ MVP)
    plan["monetize"] = infer_monetize(plan.get("category", ""))

    print("âœï¸ [Step 2] Writing (conversion-oriented)...")
    outline_items = plan.get("outline", []) or []
    outline_str = "\n".join([f"- {h}" for h in outline_items])

    # Anti-hallucination: ì¹´í…Œê³ ë¦¬ë³„ ê°€ê²© ì–¸ê¸‰ ê·œì¹™
    category = plan.get("category", "").lower()
    price_guidelines = f"""
=== PRICE & BUDGET GUIDELINES (IMPORTANT - Anti-hallucination) ===
- Use PRICE RANGES, not exact prices (e.g., "â‚©50,000-80,000" not "â‚©65,000")
- Add "as of {CURRENT_YEAR}/{CURRENT_YEAR+1}" for any price ranges
- Label uncertain prices as "typical range" and add "check current prices"
- Only include specific prices if clearly supported by the research summary above
- For budget examples, use ranges: "budget travelers: â‚©X-Y, mid-range: â‚©A-B"
"""
    
    # k-beauty/k-fashion ì¹´í…Œê³ ë¦¬ ì¶”ê°€ ê·œì¹™
    if category in ["k-beauty", "k-fashion"]:
        price_guidelines += """
- Do NOT include exact Amazon product prices or imply live Amazon pricing
- Avoid specific product costs; use phrases like "affordable range" or "premium tier"
- Focus on value comparison rather than exact numbers for products
"""

    write_prompt = f"""
Write a long-form blog post in English for a Korea travel & lifestyle blog.

Title: {plan.get('seo_title')}
Topic (Korean): {keyword}

Research summary:
{research}

Use this outline. Treat each item as an H2 heading (## ...):
{outline_str}

{price_guidelines}

Requirements:
- Start with "# {plan.get('seo_title')}" as the H1 title.
- Minimum {MIN_WORDS} words.
- Each H2 section should help with decision-making:
  - where to book, how much it costs, which option is cheaper, what to avoid.
- Use price RANGES with "as of {CURRENT_YEAR}" phrasing, not exact prices.
- Only include specific numbers if directly supported by research summary.
- Naturally include soft CTAs in text (e.g., "check current prices", "compare deals") but do NOT add actual URLs.
- Do NOT add any affiliate links or special tokens. (We will inject shortcodes separately.)
- End with a complete, encouraging sentence.

Output ONLY the Markdown content. No JSON, no backticks.
"""
    resp_content = clientOpenAI.chat.completions.create(
        model=OPENAI_MODEL,
        messages=[{"role": "user", "content": write_prompt}],
    )
    plan["content"] = clean_markdown_response(resp_content.choices[0].message.content)
    return plan


def expand_content(md: str, keyword: str) -> str:
    wc = count_words(md)
    print(f"ğŸ”§ [Expand] Current: {wc} words. Target: {MIN_WORDS}+ words.")
    prompt = f"""
You are improving an existing blog post for a Korea travel & lifestyle blog.

Goal:
- Expand the post to at least {MIN_WORDS} words.
- Keep the same title and general H2 structure.
- Do NOT remove sections. Add depth:
  - extra practical examples,
  - more price RANGES in KRW (not exact prices),
  - clearer step-by-step guidance,
  - short personal-style mini stories.

=== PRICE & BUDGET GUIDELINES (Anti-hallucination) ===
- Use PRICE RANGES, not exact prices (e.g., "â‚©50,000-80,000" not "â‚©65,000")
- Add "as of {CURRENT_YEAR}/{CURRENT_YEAR+1}" for any price ranges
- Label uncertain prices as "typical range" and add "check current prices"
- Do NOT invent specific prices not already in the draft
- Do NOT include exact Amazon product prices or imply live pricing

Topic (Korean): {keyword}

Here is the current draft (Markdown):
{md}

Return ONLY the revised Markdown. No backticks.
"""
    resp = clientOpenAI.chat.completions.create(
        model=OPENAI_MODEL,
        messages=[{"role": "user", "content": prompt}],
    )
    return clean_markdown_response(resp.choices[0].message.content)


# ==============================================================================
# 6. í‚¤ì›Œë“œ ìƒì„± (ì„±ê³¼ ê¸°ë°˜ ìµœì í™”)
# ==============================================================================

def load_last_month_performance() -> Dict[str, Any]:
    """
    ì§€ë‚œë‹¬ CSVì—ì„œ ì„±ê³¼ ë°ì´í„°ë¥¼ ë¡œë“œ.
    click_count, top_slot, best_pos ì»¬ëŸ¼ í™œìš©.
    
    Returns:
        {
            "top_keywords": [...],  # í´ë¦­ ìˆ˜ ìƒìœ„ í‚¤ì›Œë“œ
            "top_slots": [...],     # ê°€ì¥ ë§ì´ í´ë¦­ëœ ìŠ¬ë¡¯
            "best_positions": [...], # ê°€ì¥ íš¨ê³¼ì ì¸ ìœ„ì¹˜
            "patterns": [...]       # ì„±ê³¼ ì¢‹ì€ í‚¤ì›Œë“œ íŒ¨í„´
        }
    """
    from datetime import datetime, timedelta
    
    # ì§€ë‚œë‹¬ CSV íŒŒì¼ ê²½ë¡œ
    last_month = datetime.today().replace(day=1) - timedelta(days=1)
    last_month_str = last_month.strftime("%Y-%m")
    csv_path = BASE_PROJECT_DIR / f"keywords_{last_month_str}.csv"
    
    result = {
        "top_keywords": [],
        "top_slots": [],
        "best_positions": [],
        "patterns": [],
        "summary": ""
    }
    
    if not csv_path.exists():
        print(f"ğŸ“Š No performance data found for {last_month_str}")
        return result
    
    try:
        df = pd.read_csv(csv_path)
        
        # click_count ì»¬ëŸ¼ì´ ìˆëŠ” ê²½ìš°ì—ë§Œ ë¶„ì„
        if "click_count" not in df.columns:
            print(f"ğŸ“Š No click_count data in {last_month_str} CSV")
            return result
        
        # ìƒìœ„ ì„±ê³¼ í‚¤ì›Œë“œ (í´ë¦­ ìˆ˜ ê¸°ì¤€)
        top_df = df[df["click_count"] > 0].nlargest(10, "click_count")
        result["top_keywords"] = top_df["keyword"].tolist()
        
        # ê°€ì¥ íš¨ê³¼ì ì¸ ìŠ¬ë¡¯
        if "top_slot" in df.columns:
            slot_counts = df["top_slot"].value_counts()
            result["top_slots"] = slot_counts.head(3).index.tolist()
        
        # ê°€ì¥ íš¨ê³¼ì ì¸ ìœ„ì¹˜
        if "best_pos" in df.columns:
            pos_counts = df["best_pos"].value_counts()
            result["best_positions"] = pos_counts.head(3).index.tolist()
        
        # íŒ¨í„´ ì¶”ì¶œ (ê°„ë‹¨í•œ í‚¤ì›Œë“œ ë¶„ì„)
        all_keywords = " ".join(result["top_keywords"])
        common_words = ["íˆ¬ì–´", "ê°€ì´ë“œ", "ê°€ê²©", "ì˜ˆì•½", "ì¶”ì²œ", "ë§›ì§‘", "ì—¬í–‰", "ì²´í—˜"]
        patterns = [w for w in common_words if w in all_keywords]
        result["patterns"] = patterns
        
        # ìš”ì•½ í…ìŠ¤íŠ¸ ìƒì„±
        if result["top_keywords"]:
            result["summary"] = f"""
Last month's top performing keywords (by affiliate clicks):
- Keywords: {', '.join(result['top_keywords'][:5])}
- Best slots: {', '.join(result['top_slots']) if result['top_slots'] else 'N/A'}
- Best positions: {', '.join(result['best_positions']) if result['best_positions'] else 'N/A'}
- Patterns: {', '.join(result['patterns']) if result['patterns'] else 'travel/tour focused'}
"""
        
        print(f"ğŸ“Š Loaded performance data from {last_month_str}: {len(result['top_keywords'])} top keywords")
        
    except Exception as e:
        print(f"âš ï¸ Error loading performance data: {e}")
    
    return result


def generate_blog_keywords(today_str: str) -> List[str]:
    """
    í‚¤ì›Œë“œ ìƒì„± - ì§€ë‚œë‹¬ ì„±ê³¼ ë°ì´í„°ë¥¼ ë°˜ì˜í•˜ì—¬ 'ë” ëˆ ë˜ëŠ”' í‚¤ì›Œë“œ ìƒì„±.
    """
    print("ğŸ”‘ Generating keywords...")
    
    # ì§€ë‚œë‹¬ ì„±ê³¼ ë°ì´í„° ë¡œë“œ
    perf = load_last_month_performance()
    perf_context = perf.get("summary", "")
    
    prompt = f"""
Generate 50 Korean blog topics (in Korean) for an English Korea travel/lifestyle blog.
Date: {today_str}

=== MONETIZATION PRIORITY ===
Our blog earns from:
1. Tour/activity bookings (Klook, Viator) - HIGHEST VALUE
2. Hotel bookings - HIGH VALUE
3. Amazon travel essentials - MEDIUM VALUE

Generate keywords that naturally lead to these conversion opportunities.

=== LAST MONTH'S PERFORMANCE DATA ===
{perf_context if perf_context else "No previous data available. Focus on booking-intent keywords."}

=== KEYWORD REQUIREMENTS ===
Strong preference (prioritize these patterns):
- Booking intent: "OO íˆ¬ì–´ ì˜ˆì•½", "OO íŒ¨ìŠ¤ ê°€ê²©", "OO í‹°ì¼“ êµ¬ë§¤"
- Price comparison: "OO vs OO ë¹„êµ", "OO ê°€ê²© ì •ë¦¬"
- How-to guides: "OO ê°€ëŠ” ë²•", "OO ì˜ˆì•½ ë°©ë²•"
- Best/Top lists: "OO ì¶”ì²œ TOP 10", "OO ë² ìŠ¤íŠ¸"
- Seasonal: current season + upcoming events
- Location-specific: ì„œìš¸, ë¶€ì‚°, ì œì£¼ specific attractions

Avoid:
- Pure information keywords with no booking potential
- News/celebrity gossip
- Overly generic topics

Return JSON ONLY:
{{ "keywords": ["..."] }}
"""
    try:
        resp = clientOpenAI.chat.completions.create(
            model=OPENAI_MODEL,
            response_format={"type": "json_object"},
            messages=[{"role": "user", "content": prompt}],
        )
        return json.loads(resp.choices[0].message.content).get("keywords", [])
    except Exception as e:
        print(f"âŒ Keyword generation error: {e}")
        return []


# ==============================================================================
# 7. Hugo ì €ì¥
# ==============================================================================
def _yaml_list(items: List[str], indent: int = 2) -> str:
    sp = " " * indent
    if not items:
        return "[]"
    return "[{}]".format(", ".join([f'"{x}"' for x in items]))


def _yaml_block_monetize(m: Dict[str, Any]) -> str:
    """
    Front matterì— ë„£ì„ monetize ë¸”ë¡(YAML)
    """
    if not m or not m.get("verticals"):
        return ""

    intent = m.get("intent", "")
    verticals = m.get("verticals", []) or []
    slots = m.get("slots", {}) or {}
    top_slots = slots.get("top", []) or []
    bottom_slots = slots.get("bottom", []) or []

    block = [
        "monetize:",
        f'  intent: "{intent}"',
        f"  verticals: {_yaml_list(verticals, indent=2)}",
        "  slots:",
        f"    top: {_yaml_list(top_slots, indent=4)}",
        f"    bottom: {_yaml_list(bottom_slots, indent=4)}",
    ]
    return "\n".join(block)


def normalize_cover_url(url: str) -> str:
    """
    Normalize cover image URL for Hugo front matter.
    If cover.relative = true, prefer path without leading slash: images/xxx.webp
    """
    u = (url or "").strip()
    if not u:
        return ""
    # if markdown image used /images/..., strip leading slash
    if u.startswith("/"):
        u = u.lstrip("/")
    return u


def save_post(bundle: Dict[str, Any], final_md: str, cover_md: str):
    slug = bundle.get("slug", "post")
    seo_title = bundle.get("seo_title", "Korea Travel Guide").replace('"', "'")
    meta_desc = bundle.get("meta_description", "").replace('"', "'")
    category = bundle.get("category", "k-travel")
    tags = bundle.get("tags", []) or []

    # 1) cover_md (generated cover tag)ì—ì„œ url ì¶”ì¶œ
    cover_url = ""
    if cover_md:
        m = re.search(r"\((.*?)\)", cover_md)
        if m:
            cover_url = (m.group(1) or "").strip()

    # 2) âœ… fallback: ë³¸ë¬¸ ì²« ì´ë¯¸ì§€ URLì„ ì»¤ë²„ë¡œ ì‚¬ìš©
    if not cover_url:
        cover_url = extract_first_image_url(final_md)

    # 3) âœ… ìµœì¢… ì •ê·œí™” (relative: trueì— ë§ì¶¤)
    cover_url = normalize_cover_url(cover_url)

    # 4) ë””ë²„ê·¸ ë¡œê·¸ (ì™œ ë¹„ëŠ”ì§€ ë°”ë¡œ í™•ì¸ ê°€ëŠ¥)
    if not cover_url:
        print("âš ï¸ [Cover] cover_url is EMPTY. (cover generation failed + no image in content)")
    else:
        print(f"âœ… [Cover] cover_url = {cover_url}")

    monetize_block = ""
    if ENABLE_MONETIZATION:
        monetize_block = _yaml_block_monetize(bundle.get("monetize") or {})

    fm_lines = [
        "---",
        f'title: "{seo_title}"',
        f"date: {datetime.now().isoformat()}",
        f'slug: "{slug}"',
        f'description: "{meta_desc}"',
        f'categories: ["{category}"]',
        f"tags: {json.dumps(tags, ensure_ascii=False)}",
        "cover:",
        f'  image: "{cover_url}"',
        f'  alt: "{seo_title}"',
        "  relative: true",
    ]
    if monetize_block:
        fm_lines.append(monetize_block)
    fm_lines.append("---")

    fm = "\n".join(fm_lines) + "\n" + (final_md or "").rstrip() + "\n"

    path = HUGO_CONTENT_DIR / f"{datetime.now().strftime('%Y-%m-%d')}-{slug}.md"
    path.parent.mkdir(parents=True, exist_ok=True)
    path.write_text(fm, encoding="utf-8")
    print(f"âœ… Saved to: {path}")


# ==============================================================================
# 8. ë©”ì¸ ì‹¤í–‰
# ==============================================================================
if __name__ == "__main__":
    today = datetime.today()
    month_str = today.strftime("%Y-%m")
    csv_path = BASE_PROJECT_DIR / f"keywords_{month_str}.csv"

    # 1) í‚¤ì›Œë“œ ìºì‹œ ìƒì„±/ë¡œë“œ
    # CSV ì»¬ëŸ¼: keyword, done, click_count, top_slot, best_pos, slug, published_date
    if today.day == 1 or not csv_path.exists():
        keywords = generate_blog_keywords(today.strftime("%Y-%m-%d"))
        if keywords:
            df = pd.DataFrame({
                "keyword": keywords,
                "done": [False] * len(keywords),
                "click_count": [0] * len(keywords),      # GA4ì—ì„œ ìˆ˜ë™ ì…ë ¥
                "top_slot": [""] * len(keywords),        # ê°€ì¥ ë§ì´ í´ë¦­ëœ ìŠ¬ë¡¯
                "best_pos": [""] * len(keywords),        # ê°€ì¥ íš¨ê³¼ì ì¸ ìœ„ì¹˜ (top/mid/bottom)
                "slug": [""] * len(keywords),            # ë°œí–‰ëœ í¬ìŠ¤íŠ¸ slug
                "published_date": [""] * len(keywords),  # ë°œí–‰ì¼
            })
            df.to_csv(csv_path, index=False, encoding="utf-8-sig")
            print(f"ğŸ“ Created new keyword CSV with performance columns: {csv_path}")
        else:
            print("âŒ No keywords generated. Exiting.")
            raise SystemExit(1)
    else:
        df = pd.read_csv(csv_path)
        # ê¸°ì¡´ CSVì— ìƒˆ ì»¬ëŸ¼ì´ ì—†ìœ¼ë©´ ì¶”ê°€
        new_cols = {
            "click_count": 0,
            "top_slot": "",
            "best_pos": "",
            "slug": "",
            "published_date": ""
        }
        for col, default in new_cols.items():
            if col not in df.columns:
                df[col] = default
                print(f"  ğŸ“Š Added missing column: {col}")

    remaining = df[df["done"] == False]
    if remaining.empty:
        print("âœ… All keywords for this month have been processed.")
        raise SystemExit(0)

    row = remaining.sample(1)
    target_keyword = row.iloc[0]["keyword"]
    idx = row.index[0]

    print(f"\nğŸš€ Processing: {target_keyword}")

    # 2) ë¦¬ì„œì¹˜
    research_data = research_with_ai(target_keyword)

    # 3) í”Œëœ + ë³¸ë¬¸ ì‘ì„±
    bundle = create_blog_bundle(target_keyword, research_data)

    # 4) ë‹¨ì–´ ìˆ˜ ë¶€ì¡± ì‹œ í™•ì¥
    if count_words(bundle.get("content", "")) < MIN_WORDS:
        bundle["content"] = expand_content(bundle["content"], target_keyword)

    content_md = bundle["content"]

    # 5) ìƒë‹¨ ë¸”ë¡ (Disclosure + Quick Info + Top CTA)
    qi_box = build_quick_info_box(bundle.get("quick_info", {}) or {}, target_keyword)
    cta_top = build_cta_block(bundle, target_keyword, position="top")

    top_parts = []
    if ENABLE_MONETIZATION:
        disclosure = build_affiliate_disclosure_md(bundle.get("monetize") or {})
        if disclosure:
            top_parts.append(disclosure)

    top_parts.append(qi_box)

    if cta_top:
        top_parts.append(cta_top)

    top_block = "\n\n".join([p for p in top_parts if p])
    
    content_md = insert_after_h1(content_md, top_block)
    # âœ… 1) ì¤‘ë³µ H1 ë°©ì§€: ì½˜í…ì¸ ì˜ ì²« H1 ì œê±° (í…Œë§ˆê°€ H1 ë¿Œë¦°ë‹¤ê³  ê°€ì •)
    content_md = strip_first_h1(content_md)

    # âœ… 2) H1 ì—†ì´ë„ ë¬´ì¡°ê±´ ìƒë‹¨ ë¸”ë¡ ì‚½ì…
    content_md = prepend_block(content_md, top_block)

    # 6) FAQ + í•˜ë‹¨ CTA
    if "faq" in bundle:
        faq_section = build_faq_section(bundle["faq"])
        content_md = append_section(content_md, faq_section)

    cta_bottom = build_cta_block(bundle, target_keyword, position="bottom")
    if cta_bottom:
        content_md = append_section(content_md, cta_bottom)

    slug = bundle["slug"]
    title = bundle["seo_title"]

    # 7) ì»¤ë²„ ì´ë¯¸ì§€ ìƒì„±
    cover_tag = generate_image(title, f"{slug}-cover", title)

    # 8) H2 ì´ë¯¸ì§€ ì‚½ì…
    content_md = inject_images(content_md, slug, title)

    # 9) H2 ê¸°ë°˜ ì˜¤í¼ ì‚½ì… (ëˆ ë˜ëŠ” H2ì—ë§Œ)
    if ENABLE_MONETIZATION:
        content_md = inject_offers(content_md, bundle.get("monetize") or {})

    final_content = content_md
    final_content = sanitize_ai_artifacts(final_content)



    # 10) ì €ì¥
    save_post(bundle, final_content, cover_tag)

    # 11) í‚¤ì›Œë“œ ì²˜ë¦¬ ì™„ë£Œ í‘œì‹œ + ë©”íƒ€ë°ì´í„° ì €ì¥
    df.at[idx, "done"] = True
    df.at[idx, "slug"] = slug
    df.at[idx, "published_date"] = today.strftime("%Y-%m-%d")
    df.to_csv(csv_path, index=False, encoding="utf-8-sig")
    print(f"âœ¨ Done: {target_keyword} â†’ {slug}")
